h4. The EntityPersister Interface

The @EntityPersister@ interface is used to implement the basic Create, Read, Update and Delete (CRUD) operations. There are individual methods to implement such as @persistEntity@, @updateEntity@, @deleteEntity@ and so on.

In many cases there is a representation of an entity in its "native" form as supplied by the datastore driver. For example in Cassandra this could be a @ColumnFamily@, or in MongoDB a @DBCollection@. 

To support implementation such cases there is an abstract @NativeEntryEntityPersister<T, K>@ super class that provides the basis for an implementation that maps a native entry, such as a MongoDB @DBObject@ or a Neo4j @Node@ to a persist entity and back again.

The 2 generic types of this superclass indicate the native entry type (example @DBObject@ in MongoDB) and the native key type (example @ObjectId@ in MongoDB). The MongoDB implementation looks like this:

{code}
public class MongoEntityPersister extends NativeEntryEntityPersister<DBObject, Object> 
{code}

Note that @Object@ is used for the key since MongoDB also supports Long and String-based identifiers.

They key methods that need implementing are defined below:

* @getEntityFamily()@ - Defines the the name of the entity group or family. This could be a database table, a Cassandra Column Family or a MongoDB collection.
* @T createNewEntry(String family)@ - Creates a native entry ready to be inserted
* @Object getEntryValue(T nativeEntry, String property)@ - Retrieves a value of entry and returns its Java object form. For example a "date" property stored as a String in the datastore would need to b returned as a java.util.Date at this point
* @setEntryValue(T nativeEntry, String key, Object value)@ - Sets a value of the native entry, converting any Java objects to the required native format
* @deleteEntry(String family, K key, Object entry)@ - Deletes an entry for the given family, native key and entry
* @T retrieveEntry(PersistentEntity persistentEntity, String family, Serializable key)@ - Retrieves a native entry for the given entity, family and key
* @K storeEntry(PersistentEntity persistentEntity, EntityAccess entityAccess, K storeId, T nativeEntry)@ - Stores a native entry for the given id 
* @updateEntry(PersistentEntity persistentEntity, EntityAccess entityAccess, K key, T entry)@ - Updates an entry 
* @K generateIdentifier(PersistentEntity persistentEntity, T entry)@ - Generate an identifier for the given native entry
* @PropertyValueIndexer getPropertyIndexer(PersistentProperty property)@ - If the datastore requires manual indexing you'll need to implement a @PropertyIndexer@ otherwise return null
* @AssociationIndexer getAssociationIndexer(T nativeEntry, Association association)@ - If the datastore requires manual indexing you'll need to implement a @AssociationIndexer@ otherwise return null




h4. Create

The @createNewEntry@ method is used to create a native record that will be inserted into the datastore. In MongoDB this is a @DBObject@ whilst in the implementation for @ConcurrentHashMap@ it is another @Map@:

{code}
@Override
protected DBObject createNewEntry(String family) {
    return new BasicDBObject();
}
{code}

h4. Read

The @retrieveEntry@ method is used to retrieve a native record for a given key:

{code}
protected DBObject retrieveEntry(final PersistentEntity persistentEntity,
        String family, final Serializable key) {
    return mongoTemplate.execute(new DbCallback<DBObject>() {
        public DBObject doInDB(DB con) throws MongoException, DataAccessException {
            DBCollection dbCollection = con.getCollection(getCollectionName(persistentEntity));
            return dbCollection.findOne(key);
        }
    });
}
{code}

Here you can see the @MongoDB@ implementation that uses a Spring Data @MongoTemplate@ to find a @DBObject@ for the given key. There is a separate @storeEntry@ method that is used to actually store the native object. In @MongoDB@ this looks like:

{code}
@Override
protected Object storeEntry(final PersistentEntity persistentEntity, final EntityAccess entityAccess,
                            final Object storeId, final DBObject nativeEntry) {
    return mongoTemplate.execute(new DbCallback<Object>() {
        public Object doInDB(DB con) throws MongoException, DataAccessException {
            nativeEntry.put(MONGO_ID_FIELD, storeId);
            return storeId;
        }
    });
}
{code}

Notice it doesn't actually do anything native insert into a MongoDB collection. This is because the Datastore API supports the notion of batch insert operations and flushing. In the case of @MongoDB@ the @MongoSession@ implementation overrides the @flushPendingInserts@ method of @AbstractSession@ and performs a batch insert of multiple MongoDB documents (ie @DBObject@s) at once:

{code}
collection.insert(dbObjects.toArray(new DBObject[dbObjects.size()]), writeConcernToUse);
{code}

Other datastores that  do not support batch inserts would instead to the insert in the @storeEntry@ method itself. For example the implementation for @ConcurrentHashMap@ looks like (note Groovy code):

{code}
protected storeEntry(PersistentEntity persistentEntity, EntityAccess entityAccess, storeId, Map nativeEntry) {
    if (!persistentEntity.root) {
        nativeEntry.discriminator = persistentEntity.discriminator
    }
    datastore[family].put(storeId, nativeEntry)
    return storeId
}
{code}

h4. Update

The @updateEntry@ method is used to update an entry:

{code}
public void updateEntry(final PersistentEntity persistentEntity, final EntityAccess ea,
        final Object key, final DBObject entry) {
    mongoTemplate.execute(new DbCallback<Object>() {
        public Object doInDB(DB con) throws MongoException, DataAccessException {
            String collectionName = getCollectionName(persistentEntity, entry);
            DBCollection dbCollection = con.getCollection(collectionName);
            if (isVersioned(ea)) {
                // TODO this should be done with a CAS approach if possible
                DBObject previous = dbCollection.findOne(key);
                checkVersion(ea, previous, persistentEntity, key);
            }

            MongoSession mongoSession = (MongoSession) session;
            dbCollection.update(dbo, entry, false, false, mongoSession.getWriteConcern());
            return null;
        }
    });
}
{code}

As you can see again the underlying database specific @update@ method is used, in this case the @DBCollection@'s @update@ method.

h4. Delete

The @deleteEntry@ method is used to delete an entry. For example in the @ConcurrentHashMap@ implementation it is simply removed from the map:

{code}
protected void deleteEntry(String family, key, entry) {
    datastore[family].remove(key)
}
{code}

Whilst in @MongoDB@ the @DBCollection@ object's @remove@ method is called:

{code}
@Override
protected void deleteEntry(String family, final Object key, final Object entry) {
    mongoTemplate.execute(new DbCallback<Object>() {
        public Object doInDB(DB con) throws MongoException, DataAccessException {
            DBCollection dbCollection = getCollection(con);

            MongoSession mongoSession = (MongoSession) session;
            dbCollection.remove(key, mongoSession.getWriteConcern());
            return null;
        }

        protected DBCollection getCollection(DB con) {
            return con.getCollection(getCollectionName(getPersistentEntity()));
        }
    });
}
{code}

Note that if the underlying datastore supports batch delete operations you may want override and implement the @deleteEntries@ method which allows for deleting multiple entries in a single operation. The implementation for MongoDB looks like:

{code}
protected void deleteEntries(String family, final List<Object> keys) {
    mongoTemplate.execute(new DbCallback<Object>() {
        public Object doInDB(DB con) throws MongoException, DataAccessException {
            String collectionName = getCollectionName(getPersistentEntity());
            DBCollection dbCollection = con.getCollection(collectionName);

            MongoSession mongoSession = (MongoSession) getSession();
            MongoQuery query = mongoSession.createQuery(getPersistentEntity().getJavaClass());
            query.in(getPersistentEntity().getIdentity().getName(), keys);

            dbCollection.remove(query.getMongoQuery());

            return null;
        }
    });
}
{code}

You'll notice this implementation uses a @MongoQuery@ instance. Note that implementing an @EntityPersister@ you have enabled basic CRUD operations, but not querying, which is a topic of the following sections. First, however secondary indices need to covered since they are required for querying.